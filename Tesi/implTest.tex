\chapter{Implementazione e test}
\label{chap:implTest}

\begin{minipage}{12cm}\textit{In questo capitolo si illustreranno gli aspetti tecnici relativi alla realizzazione del software: la scelta delle librerie e dell'ambiente di sviluppo, i problemi riscontrati e le soluzioni intraprese. Si procederà inoltre alla validazione del sistema e la valutazione delle prestazioni.}
\end{minipage}

\vspace*{1cm}

\section{Lo sviluppo}
\label{sec:sviluppo}
Nei precedenti capitoli si è discusso principalmente degli strumenti teorici che, come spesso segnalato, sono stati selezionati o sintetizzati con in mente il requisito di efficienza imprescindibile in un contesto di controllo nel quale ci si pone. Sono stati selezionati perciò gli algoritmi migliori rispetto ad un rapporto efficacia/costo computazionale. Inoltre, si sono scelti quelli meglio parallelizzabili su architetture vettorizzate o dotate di co-processori grafici. Nel seguito verrà descritto l'aspetto implementativo del software Visual Observer. Si descriveranno in particolare gli strumenti di sviluppo, le librerie usate e l'architettura software implementata. 

\subsection{Ambiente di sviluppo e target}
\label{sec:dev:ambiente}

Prima di poter scrivere anche una sola linea di codice, si deve aver ben chiaro l'obbiettivo di sviluppo che ci si pone al fine di poter valutare quale può essere l'ambiente di sviluppo, il linguaggio e le librerie da utilizzare.  Conviene allora specificare e definire i requisiti di progetto:
\begin{itemize}
	\item \textbf{Architettura target:}  x86\_64, ARM,
	\item \textbf{Sistema Operativo target:}  Windows, GNU/Linux,
	\item \textbf{Specifiche hardware minime:}
	\begin{itemize}
		\item CPU: x86\_64 o ARM,
		\item GPU: nessuna o generica con supporto OpenCL,
	\end{itemize} 
	\item \textbf{Specifiche hardware consigliate:}
		\begin{itemize}
			\item CPU: x86\_64 o ARM con supporto OpenCL o SIMD/AVX,
			\item GPU: coprocessore grafico NVidia ad alte prestazioni con supporto CUDA Shared Model $\ge$ 2.1,
		\end{itemize}			 
\end{itemize}

La scelta delle architetture e dei sistemi operativi non è casuale, ovviamente. Infatti, il supporto x86\_64 permette di poter sviluppare e testare il codice su un normale PC in ambiente Windows o Linux. D'altro canto il software è pensato per essere utilizzato a bordo di un sistema di controllo di un robot e tipicamente quest'ultimi hanno processori ARM su sistema Linux.

Spesso si è fatto riferimento nei capitoli precedenti ad un requisito di esecuzione real-time. Formalmente esso è difficile da definire, si può intendere però nel seguente modo: \textit{si fissi una piattaforma hardware abbastanza potente, si richiede che il tempo di esecuzione del software di stima sia tale da rendere la stessa disponibile in tempo utile.} Ad esempio, su sistemi moderni si potrebbe richiedere che sia in grado si fornire una stima con frequenza 20 Hz o superiore.
 
Si può comprendere allora la specifica richiesta della presenza di un processore vettorizzato o un coprocessore grafico con supporto a OpenCL o CUDA. Infatti, in questi casi è possibile ridurre di moltissimo i tempi di esecuzione grazie alla parallelizzazione dei calcoli.

Alla luce di quanto su detto, la scelta del linguaggio di sviluppo è ricaduta sul \textbf{C++}. Infatti esso permette di ottenere un codice macchina particolarmente ottimizzato e al contempo di mantenere la portabilità dello stesso. Il codice è stato sviluppato utilizzando il sistema operativo \textbf{Windows} e l'ambiente di sviluppo \textbf{Visual Studio Community 2015}. Tale scelta è motivata da diversi fattori:
\begin{enumerate}
	\item Allo stato attuale, Visual Studio permette di sviluppare e compilare codice, in modo semplice, per tutti i sistemi operativi e le architetture su citati.
	\item In ambiente Linux non si sarebbe potuto sviluppare per Windows.
	\item Rende lo sviluppo più semplice e veloce, grazie anche a numerosi strumenti di debug e profiling messi a disposizione.
	\item Per scopi accademici (e piccoli progetti commerciali) è distribuito gratuitamente.
\end{enumerate}

Nel seguito si presenta una breve descrizione delle librerie software utilizzate: OpenCV e CUDA. Non si farà riferimento a OpenCL perché non direttamente utilizzata. Infatti, grazie all'uso di OpenCV l'utilizzo della stessa o di un altro sistema di vettorizzazione è del tutto trasparente. Come sarà chiaro più avanti nel paragrafo dedicato al testing, l'attivazione o meno di quest'ultima però darà luogo a prestazioni nettamente superiori. Informalmente, OpenCL è un architettura hardware e software per il calcolo parallelo. Essa permette di utilizzare sia CPU che GPU (anche Nvidia), talvolta in contemporanea, per effettuare calcoli generici.

\subsection{OpenCV}
\label{sec:tools:opencv}

OpenCV, acronimo in lingua inglese di \textbf{Open} source \textbf{C}omputer \textbf{V}ision library, è una libreria software multi piattaforma per la visione artificiale. Essa nella sua prima versione risale al lontano 2000 ed è stata originariamente sviluppata ad opera di Intel. Successivamente il progetto è stato preso in carico dalla comunità open source ed è mantenuto da un numero elevato di appassionati e sviluppatori. Oggi giorno, è considerata lo standard di fatto utilizzato per progetti comprendenti la visione artificiale in progetti sia accademici che commerciali. Essa comprende molteplici ambiti tra cui: calcolo matriciale e strumenti di algebra lineare, riconoscimento delle feature, stereoscopia e filtraggio delle immagini. Di giorno in giorno gli strumenti presenti vengono ottimizzati e di nuovi ne vengono aggiunti. 
La libreria è scritta principalmente in codice C++, fortemente ottimizzato per sfruttare le particolarità della piattaforma target: vettorizzazione SIMD e AVX, openCL, CUDA. Risulta perciò un valido strumento in progetti di applicazioni real-time. Esistono poi numerosi wrapper che permettono il suo impiego in altri linguaggi tra cui: Python, Java, C\#. Inoltre è disponibile per praticamente tutti i maggiori sistemi operativi: Windows, Linux, Android, IOs e OsX e per le maggiori architetture: x86, x86\_64, ARM.
Infine si segnala che è rilasciata sotto licenza BSD perciò può essere liberamente impiagata in progetti sia accademici che commerciali.

\subsection{CUDA}
\label{sec:tools:cuda}
CUDA (acronimo di Compute Unified Device Architecture) è un'architettura hardware per l'elaborazione parallela creata da NVIDIA. Essa, unitamente all'ambiente di sviluppo CUDA, permette scrivere applicazioni capaci di eseguire calcolo parallelo sulle GPU Nvidia. I linguaggi di programmazione disponibili nell'ambiente di sviluppo per CUDA, sono estensioni dei linguaggi più diffusi per scrivere programmi. Il principale è "CUDA-C" (C con estensioni NVIDIA), altri sono estensioni di Python, Fortran, Java e MATLAB.

Diversamente dalle CPU, le GPU hanno un'architettura parallela con diversi core, ognuno capace di eseguire centinaia di processi simultaneamente, se un'applicazione è adatta per quel tipo di architettura la GPU può offrire grandi prestazioni e benefici. Questo approccio di risoluzione dei problemi è noto come GPGPU (General Purpose GPU). In generale un ottimo contesto di esecuzione per questo tipo di dispositivi è quando vengono avviati moltissimi thread con lo stesso flusso di esecuzione. In realtà infatti le GPU estremizzano il concetto di vettorizzazione. Si hanno a disposizione un certo numero di Shared Processor, capaci di eseguire un gruppo di thread alla volta detto Warp. Per poter eseguire un Warp in modo parallelo deve accadere che tutti i thread che lo compongono eseguano le stesse operazioni, ovviamente su indirizzi di memoria differenti. Inoltre per rendere gli accessi in memoria efficienti e ridurre (anche drasticamente) i tempi di calcolo i thread devono poter accedere alla memoria in modo adatto. Infatti, le GPU gestiscono la memoria in modo opposto rispetto alle CPU, cioè locazioni di memoria vicine sono disposte in diversi banchi di memoria. Il motivo di tale scelta risiede nel fatto che le richieste in memoria sono solitamente molto lente e si cerca di parallelizzare la lettura in memoria al fine di rendere i dati disponibili simultaneamente per tutti i thread di un Warp. 

Alla luce di ciò, è chiaro che non tutte le applicazioni possono essere parallelizzate su coprocessore grafico ed è inoltre chiaro perché un forte accento si è posto sul trovare algoritmi parallelizzabili. Ad esempio questo è il caso del comparatore a forza bruta, presentato nel paragrafo \ref{sec:det:bmmatch}, che seppur utilizza un approccio poco intelligente risulta molto veloce.

\subsection{L'architettura software}
\label{sec:dev:arch}
Infine, per concludere il paragrafo, si presenta l'architettura software sviluppata. Essa è pensata per essere completamente modulare ed intercambiabile. I blocchi funzionali contraddistinti con la lettera "I" maiuscola sono delle interfacce e diverse implementazioni ne sono fornite.
\begin{figure}[h!]
	\centering
	\includegraphics[width=400pt]{imgs/arch.png}
	\caption{Rappresentazione architettura software Visual Observer.}
	\label{vis:impl:arch}
\end{figure} 

L'architettura inoltre prevede che essi possano essere sostituiti da future implementazioni. Con riferimento alla figura \ref{vis:impl:arch} è possibile verificare che il sistema Visual Observer si compone di tre principali blocchi funzionali: 
\begin{enumerate}
	\item \textbf{Camera Manager}: ha lo scopo di gestire le camere e astrarre l'acquisizione dell'input visuale verso il Visual Observer. Esso può inoltre gestire più camere anche di diverso tipo. Le camere possono essere registrate attraverso l'interfaccia \textbf{ICamera} e un identificativo univoco. In tal modo è possibile richiedere al manager di acquisire un immagine da un determinato sensore. Si è prevista inoltre la possibilità di richiedere l'input sincrono da parte di due sensori grafici allo scopo di ottenere una coppia di immagini stereo catturate nello stesso istante.
	L'interfaccia ICamera astrae il manager dal funzionamento del sensore stesso e permette quindi l'utilizzo di sensori di diverso tipo senza dover modificare il codice a monte. Tale interfaccia espone diversi metodi tra cui: calibrazione, acquisizione grezza e acquisizione rettificata. Il primo metodo è pensato per eseguire la calibrazione del sensore e quindi la stima dei parametri di distorsione cui si è accennato nel capitolo \ref{chap:visione}. Il secondo ed il terzo pensati per richiedere la cattura di un immagine o di una rettificata rispettivamente, utilizzando i parametri ottenuti in fase di calibrazione. Per gestire una camera è necessario quindi implementare tale interfaccia e scrivere il codice necessario solo alla gestione del sensore che si vuole utilizzare. Potrebbe essere quindi necessario, a seconda del sensore, dover scrivere un driver o semplicemente dialogare con uno già esistente. In figura \ref{vis:impl:arch} ad esempio sono stati collegati due sensori USB.
	
	\item \textbf{IEstimator}: è un astrazione dell'algoritmo di stima della matrice di trasformazione che si vuole utilizzare. Espone a monte solo i metodi atti all'introduzione dell'input, richiesta della stima ed estrazione dell'output. Si è previsto quindi di poter cambiare, anche durante l'esecuzione, l'algoritmo usato. Questo meccanismo risulta molto utile soprattutto in fase di test, è possibile sperimentare i risultati ottenuti utilizzando diversi algoritmi. Inoltre, in una futura estensione si potrebbe prescindere dagli algoritmi implementati ed utilizzarne degli altri senza apportare ancora una volta nessuna modifica a monte.
	
	Si sono quindi implementati i diversi algoritmi di stima presentati nel capitolo \ref{chap:stima} ed è possibile scegliere quale utilizzare. Per l'algoritmo di Kabsch ad esempio si è sperimentato con diverse implementazioni, una su CPU e un altra che fa uso del processore grafico.
	
	\item \textbf{ISetsGenerator}: questo blocco funzionale è adibito alla generazione dei set di coordinate dei punti omologhi cui si è discusso nel capitolo \ref{chap:visione}. Accetta in ingresso l'input visivo e restituisce a monte i set suddetti senza esibire nulla riguardo il suo funzionamento interno. In figura \ref{vis:impl:arch} si può evincere che ad esso è collegato un ulteriore blocco funzionale IPairsGenerator. In effetti questo tipo di collegamento non è obbligatorio, diverse implementazioni potrebbero anche farne a meno ma si è preferito segnalarne il possibile collegamento, dato che in effetti nell'implementazione attuale viene utilizzato. Con ordine quindi:
	\begin{itemize}
		\item \textbf{IPairsGenerator}: è un astrazione dell'algoritmo adibito alla ricerca di corrispondenze in due immagini. Concettualmente, accetta due immagini in ingresso e fornisce le corrispondenze tra i punti chiave trovati. Si è implementato quanto detto nel capitolo \ref{chap:visione}: FAST + BRIEF + BF matcher. Si sono previste, scrivendo codice OpenCV, implementazioni che fanno uso sia della vettorizzazione su CPU e/o utilizzano OpenCL. Inoltre per i sistemi dotati di processore grafico Nvidia si è previsto l'utilizzo di un implementazione CUDA.
		\item Inoltre si è implementato un ISetsGenerator che, in concordanza a quanto detto nel paragrafo \ref{sec:vision:solution}, fa uso degli IPairsGenerator forniti al fine di generare i suddetti set.
	\end{itemize}
	Tutto il codice implementato risulta modulare e può essere modificato o sostituito senza necessità di riscrivere il codice di gestione. Visual Observer può essere stanziato specificando quale implementazione utilizzare a seconda delle necessità o delle disponibilità hardware. Per quanto riguarda il funzionamento ad alto livello esso si limita ad utilizzare i livelli sottostanti senza necessità di conoscerne il funzionamento, dimostrando così il potenziale che un architettura a livelli di astrazione può fornire. In particolare, si utilizza il manager per richiedere un nuovo input dall'esterno dai sensori frontali o da una qualsiasi altra coppia sensori. L'input ottenuto viene fornito poi all'ISetsGenerator che restituisce i due set di coordinate. Quest'ultimi vengono infine passati all'IEstimator per ottenere la stima vera e propria che può essere poi fornita a monte ad un qualsivoglia controllore o osservatore.
	 
\end{enumerate}
\section{Validazione e test}
\label{sec:test}

\subsection{Il motore grafico Unity3D}
\label{sec:unity}

\subsection{Vantaggi e svantaggi di una validazione con motore grafico}
\label{sec:valid}

\subsection{Risultati ottenuti}
\label{sec:perf}